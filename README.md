# Projeto_NLP_NER_Juridico
O projeto avalia o desempenho de quatro modelos transformers pr´e-treinados (BERT-base, BERT-large, RoBERTa-base e RoBERTa-large) na tarefa de Reconhecimento de Entidades Nomeadas (NER) em textos jurídicos do corpus LeNER-Br.O dataset foi particionado para treino, validacão e teste, e cada modelo foi submetido a fine-tuning com otimizador, treinamento por 10 ´epocas e early stopping baseado na métrica F1 de validacão¸ Os melhores checkpoints de cada experimento foram versionados no Hugging Face Hub e consumidos em notebooks de token classification, que realizaram a tokenizacão, o alinhamento preciso de tokens com rótulos e a avaliacão com as bibliotecas Evaluate e Seqeval. Os resultados mostram que o BERT-large alcançou o melhor F1 global, seguido pelo BERT-base, enquanto RoBERTa-base e RoBERTa-large apresentaram menores percentuais de F1, evidenciando um trade-off entre capacidade do modelo e tamanho do dataset. Para demonstrar a aplicabilidade prática, foi desenvolvida uma interface web em Gradio que destaca automaticamente as entidades reconhecidas no texto jurídico submetido pelo usuário.
